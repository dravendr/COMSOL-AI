{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sko.GA import GA\n",
    "from sko.PSO import PSO\n",
    "import time\n",
    "from keras.models import Model, load_model\n",
    "from sko.GA import GA\n",
    "from sko.DE import DE\n",
    "from sklearn import tree\n",
    "%matplotlib\n",
    "###########assign memory##########\n",
    "###########delete this part if your tensorflow was based on CPU##########\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.45\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config)) \n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "np.random.seed(seed)\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[                     \n",
    "                      'A_c',#0\n",
    "                      'A_a',#1\n",
    "                      'L_cl',#2\n",
    "                      'i0',#3\n",
    "                      'L-PEM',#4\n",
    "                      'L_GDL',#5\n",
    "                      'epsl_cl',#6\n",
    "                      'epsp_cl',#7\n",
    "                      'T_cc',#8\n",
    "                      'RH_cc',#9\n",
    "                      'pressure',#10\n",
    "                        'Volt0.9',\n",
    "                        'Volt0.8',\n",
    "                        'Volt0.7',#13\n",
    "                        'Volt0.6',\n",
    "                        'Volt0.5',\n",
    "                        'Volt0.4',\n",
    "                        'Volt0.3',\n",
    "                        'Volt0.2',\n",
    "                        'Volt0.1',\n",
    "                        'Volt0'\n",
    "                        ]]\n",
    "###########data standardization##########\n",
    "standardized_data = (raw_data-np.mean(raw_data,axis=0))/np.std(raw_data,axis=0)\n",
    "\n",
    "###########defining a wrapper function for later call from each machine learning algorithms##########\n",
    "raw_input=standardized_data.iloc[:,0:11]\n",
    "raw_output=standardized_data.iloc[:,11:]\n",
    "X=raw_input.values.astype(np.float32)\n",
    "y=raw_output.values.astype(np.float32)\n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "###########train test splitting##########\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15,random_state=seed)\n",
    "raw_input_global=raw_data.iloc[:,0:11]\n",
    "raw_output_global=raw_data.iloc[:,11:]\n",
    "###########wrap up fuction for later call for OPTIMIZATION##########\n",
    "def evaluate(pre_2,real_2):\n",
    "    pre_2=np.array(pre_2)\n",
    "    real_2=np.array(real_2)\n",
    "    pre_2_series=pd.Series(pre_2)\n",
    "    real_2_series=pd.Series(real_2)\n",
    "    return rmse(pre_2,real_2), round(pre_2_series.corr(real_2_series), 3)\n",
    "def compare(list_name,limit):\n",
    "    judge=1\n",
    "    for a in list_name:\n",
    "        if a < limit:\n",
    "            judge=judge*1\n",
    "        else:\n",
    "            judge=judge*0\n",
    "    return judge\n",
    "def generate_arrays_from_file(path):\n",
    "    while True:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                # create numpy arrays of input data\n",
    "                # and labels, from each line in the file\n",
    "                x1, x2, y = process_line(line)\n",
    "                yield ({'input_1': x1, 'input_2': x2}, {'output': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('ANN_CURVE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_PRINT(thickness):\n",
    "    median=standardized_data.median()\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:11]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=1.872e7\n",
    "    user_input1.iloc[1]=1.872e7\n",
    "    user_input1.iloc[2]=thickness\n",
    "    user_input1.iloc[3]=24.5\n",
    "    user_input1.iloc[4]=23\n",
    "    user_input1.iloc[5]=125\n",
    "    user_input1.iloc[6]=0.19\n",
    "    user_input1.iloc[7]=0.64\n",
    "    user_input1.iloc[8]=353.15\n",
    "    user_input1.iloc[9]=1\n",
    "    user_input1.iloc[10]=300000\n",
    "    standardized_user_input1=(user_input1-np.mean(raw_data,axis=0)[0:11])/np.std(raw_data,axis=0)[0:11]\n",
    "    data_test_input1=standardized_user_input1\n",
    "    data_test_input1=pd.DataFrame(data_test_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "    data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model.predict(data_test_param1)\n",
    "    ###########result output##########\n",
    "    predict_ann=predict_ann*np.std(raw_output_global,axis=0).T.values+np.mean(raw_output_global,axis=0).T.values\n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "    x_prediction_ann=x_prediction_ann.tolist()\n",
    "    x_prediction_ann=x_prediction_ann[0]\n",
    "#     print(x_prediction_maximum_power_ann)\n",
    "    x_07=x_prediction_ann[2]\n",
    "    dict_result.update({x_07:{\n",
    "                                'thickness':thickness}})\n",
    "    print(x_07)\n",
    "\n",
    "    return x_07, dict_result\n",
    "import time\n",
    "time_start = time.time()\n",
    "for i in np.arange(1,15,0.01):\n",
    "    processing_PRINT(i)\n",
    "\n",
    "time_end = time.time()\n",
    "print('Time cost of grid search= %fs' % (time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "def processing_curve_ic(a,thickness,epsl_cl,epsp_cl):\n",
    "    median=standardized_data.median()\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:11]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=a\n",
    "    user_input1.iloc[1]=a\n",
    "    user_input1.iloc[2]=thickness\n",
    "    user_input1.iloc[3]=24.5\n",
    "    user_input1.iloc[4]=23\n",
    "    user_input1.iloc[5]=125\n",
    "    user_input1.iloc[6]=epsl_cl\n",
    "    user_input1.iloc[7]=epsp_cl\n",
    "    user_input1.iloc[8]=353.15\n",
    "    user_input1.iloc[9]=1\n",
    "    user_input1.iloc[10]=300000\n",
    "    standardized_user_input1=(user_input1-np.mean(raw_data,axis=0)[0:11])/np.std(raw_data,axis=0)[0:11]\n",
    "    data_test_input1=standardized_user_input1\n",
    "    data_test_input1=pd.DataFrame(data_test_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "    data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model.predict(data_test_param1)\n",
    "    ###########result output##########\n",
    "    predict_ann=predict_ann*np.std(raw_output_global,axis=0).T.values+np.mean(raw_output_global,axis=0).T.values\n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "    x_prediction_ann=x_prediction_ann.tolist()\n",
    "    x_prediction_ann=x_prediction_ann[0]\n",
    "    return x_prediction_ann[0:]\n",
    "a_list=[18720000,15709969.79, 6514522.822, 17476538.06, 17958179.58]\n",
    "thickness_list=[5, 5.627, 9.64, 4.795, 4.878]\n",
    "epsl_list=[0.190349291, 0.212508265, 0.921469597, 0.11578424, 0.151752202]\n",
    "epsp_list=[0.640081927, 0.636817502, 0.01, 0.707397426, 0.674438058]\n",
    "voltage_list=[0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]\n",
    "for i in range (0,5):\n",
    "    print(processing_curve_ic(a_list[i],thickness_list[i],epsl_list[i],epsp_list[i]))\n",
    "    print(get_power_density(processing_curve_ic(a_list[i],thickness_list[i],epsl_list[i],epsp_list[i]),voltage_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
